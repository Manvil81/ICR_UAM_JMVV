\chapter{Estado del arte \label{cap:EstadoDelArte}}

\noindent
Es utilizada principalmente la bibliografía encontrada en el capítulo anterior referente a la predicción probabilista sísmica utilizando el método de distribución logaritmo normal y gama, distribuciones de valores extremos como Gumbel, Weibull y GEV, así como bibliografía publicada que ahonda en la aplicación práctica para solución de problemas basados en fórmulas y cálculos derivados de la probabilidad y la estadística, y sus variables dependientes necesarias para realizar los cálculos.

Todo esto es aplicado a la solución del problema desde un enfoque que utiliza las técnicas conocidas y los datos estadísticos específicos para el problema a resolver.

\section{Revisión del estado del arte}

\noindent
En esta sección se presenta una revisión del estado del arte de los trabajos más relevantes para este proyecto, con el propósito de enriquecer la metodología propuesta.

Los terremotos son vibraciones de la corteza terrestre \cite{abebe2023earthquakes}, las cuales pueden provocar temblores, incendios, deslizamientos de tierra y fracturas en el terreno que representan riesgos para las personas que viven en áreas consideradas como altamente sísmicas \cite{abebe2023earthquakes,velascoherrera2022long}. Es por esto que constantemente se realizan análisis estadísticos y geográficos para este tipo de eventos naturales \cite{barrientos2007analisis}, así como evaluaciones probabilísticas de la peligrosidad sísmica \cite{sawires2023probabilistic}, con la finalidad de disminuir o prevenir los desastres que estos ocasionan. Dichos estudios permiten estimar magnitudes en la escala de Richter \cite{richter1935instrumental} o calcular probabilidades de ocurrencia de futuros terremotos \cite{abebe2023earthquakes,albanna2020application,ferraes2005probabilistic,jena2021earthquake,matsumoto2023fundamental,singh2021ground,tareen2019descriptive,velascoherrera2022long}.

Dentro de las distintas formas de realizar inferencia y predicción sísmica se han desarrollado técnicas basadas en IA \cite{albanna2020application} para identificar patrones ocultos en los datos sísmicos, o también técnicas derivadas de la IA como los algoritmos transformer aplicados a series temporales \cite{abebe2023earthquakes}. De igual forma, los enfoques que se basan en deep learning o aprendizaje profundo \cite{abebe2023earthquakes,jena2021earthquake,matsumoto2023fundamental} se emplean para realizar mapeos de riesgo y la predicción de eventos sísmicos. También se aplican técnicas basadas en el uso de redes neuronales convolucionales \cite{jena2021earthquake}, las cuales evalúan la probabilidad de ocurrencia de un terremoto.

Estas técnicas generalmente se cimentan en análisis matemáticos, probabilistas y estadísticos \cite{convertito2021time,matsumoto2023fundamental,sawires2023probabilistic,velascoherrera2022long} para realizar estimaciones de futuros eventos sísmicos, tanto para profundidades relativamente bajas y magnitudes pequeñas \cite{convertito2021time} como para desarrollar modelos de generación de movimiento del suelo mediante GANs \cite{matsumoto2023fundamental} y ecuaciones de predicción del movimiento del suelo (GMPE) específicas para Taiwán y el Himalaya occidental \cite{phung2020ground,singh2021ground}. La teoría de valores extremos (extreme value theory, EVT) ha emergido como uno de los marcos teóricos más robustos para el análisis de eventos sísmicos raros de gran magnitud \cite{coles2001introduction,coles2021extreme,mignan2021best}, proporcionando fundamentación matemática sólida para la predicción probabilística de terremotos.

El análisis de valores extremos se sustenta principalmente en dos enfoques metodológicos: el método de máximos anuales y el de excedencias sobre umbral (peak-over-threshold). \citeasnoun{bommier2023peak} demuestra que, para conjuntos de datos históricos con menos de 150 años de registros (como es común en sismología), el método de máximos anuales utilizando distribuciones GEV, Gumbel o Weibull resulta más robusto y confiable que el enfoque POT. Este hallazgo respalda la selección metodológica adoptada en numerosos estudios sísmicos que emplean magnitudes máximas anuales como variable de análisis \cite{mignan2021best,yaghmaeisakbegh2022regional,ramirezgaytan2021earthquake}.

Con respecto a estos cálculos matemáticos y estadísticos, se utilizan técnicas como los modelos lineales de tipo log-lineal \cite{barrientos2007analisis}, log-normales \cite{ferraes2005probabilistic}, y modelos no Poisson como Brownian Passage Time (BPT), Weibull, distribución gamma y el modelo Epidemic Type Aftershock Sequence (ETAS) \cite{convertito2021time,ferraes2005probabilistic}. La selección de la distribución probabilística más apropiada para cada región se realiza mediante criterios estadísticos rigurosos como el Criterio de Información Bayesiano (BIC) y el Criterio de Información de Akaike (AIC), complementados con pruebas de bondad de ajuste como Kolmogorov-Smirnov, Anderson-Darling y Lilliefors \cite{bommier2023peak,yaghmaeisakbegh2022regional}. La evaluación de la adecuación de diferentes distribuciones a datos de valores extremos, incluso en áreas distintas a la sismología como los niveles máximos de inundación, se realiza mediante análisis comparativos \cite{shobanke2024comparative}. Igualmente, se han empleado la distribución de Venn para determinar el peligro de un sismo futuro \cite{jena2021earthquake}, los estadísticos descriptivos de series temporales de radón en el suelo \cite{tareen2019descriptive}, y el aprendizaje automático bayesiano \cite{velascoherrera2022long}. Un aspecto crucial de todos estos análisis es la aplicación de pruebas de hipótesis y la construcción de intervalos de confianza para validar las conclusiones y estimar la incertidumbre de los parámetros \cite{shreffler2025hypothesis}, empleando técnicas de bootstrap paramétrico que han demostrado ser particularmente efectivas para la cuantificación de incertidumbre en estimaciones de valores extremos \cite{papalexiou2020random,rootzen2021efficient}.

La implementación de bootstrap paramétrico para la construcción de intervalos de confianza en análisis de valores extremos ha sido objeto de investigación metodológica específica. \citeasnoun{papalexiou2020random} demuestran mediante experimentos de Monte Carlo que 10,000 iteraciones bootstrap proporcionan un equilibrio óptimo entre precisión estadística y eficiencia computacional para distribuciones de valores extremos, con mejoras marginales al incrementar a 20,000 iteraciones. \citeasnoun{rootzen2021efficient} complementan estos hallazgos proporcionando fundamentación matemática sobre la convergencia de estimadores bootstrap y expresiones analíticas para el error de Monte Carlo, validando que 10,000 iteraciones son suficientes para alcanzar errores estándar menores al 0.5\% en los percentiles extremos que definen los intervalos de confianza al 95\%.

El cálculo de períodos de retorno y probabilidades de excedencia constituye un componente esencial de la evaluación probabilística de peligrosidad sísmica. \citeasnoun{mignan2021best} desarrollan metodologías para el cálculo de niveles de retorno en horizontes temporales de 10, 50, 100 y 475 años (este último utilizado en códigos de construcción internacional), implementando intervalos de confianza mediante bootstrap paramétrico. \citeasnoun{serinaldi2021understanding} formalizan la expresión para la probabilidad de que al menos un evento exceda una magnitud $M$ en los próximos $\Delta t$ años: $P(\text{excedencia en } \Delta t \text{ años}) = 1 - [F(M)]^{\Delta t}$, donde $F(M)$ es la función de distribución acumulada, y demuestran su aplicabilidad a procesos de renovación con memoria temporal. Estos enfoques permiten estimar no solo la magnitud esperada en diferentes horizontes temporales, sino también la probabilidad de que eventos específicos ocurran dentro de ventanas temporales de interés para la planificación y mitigación del riesgo.

El análisis temporal de la actividad sísmica y el concepto de brecha sísmica han ganado relevancia en años recientes como complemento a los modelos puramente probabilísticos. \citeasnoun{sanchezsilva2020real} implementan modelos de renovación que calculan un índice de proximidad temporal (IPT) definido como la razón entre el tiempo transcurrido desde el último evento significativo y el tiempo medio de recurrencia histórica, estableciendo umbrales para clasificación de riesgo. \citeasnoun{ramirezgaytan2021earthquake} aplican esta metodología específicamente a la brecha sísmica de Michoacán utilizando datos del SSN desde 1900, introduciendo además el coeficiente de variación ($CV = \sigma/\mu$) para cuantificar la regularidad temporal: $CV < 0.5$ indica recurrencia cuasi-periódica apropiada para modelos de renovación, mientras que $CV \geq 1.0$ sugiere procesos cercanos a Poisson. \citeasnoun{singh2020deadly} validan retrospectivamente estos enfoques con el análisis del sismo de Puebla 2017, demostrando que eventos considerados ``inesperados'' bajo modelos de Poisson resultan predecibles cuando se incorpora memoria temporal mediante modelos de renovación.

La construcción de índices compuestos de peligrosidad sísmica que integren múltiples factores de riesgo representa una tendencia metodológica reciente. \citeasnoun{convertito2020combining} desarrollan un índice que combina la magnitud esperada según modelos de valores extremos, probabilidades de excedencia en diferentes horizontes temporales, tiempo desde el último evento significativo y tasa histórica de actividad, validando retrospectivamente sus predicciones con eventos ocurridos entre 2016 y 2019 en Italia. \citeasnoun{zuniga2022first} proponen una regionalización sismotectónica de México que emplea un índice similar, normalizando cuatro componentes (nivel de retorno a 50 años, probabilidad de exceder M$\geq$7.0 en 10 años, índice de proximidad temporal y magnitud promedio histórica) para generar clasificaciones objetivas de peligrosidad por región. Estos índices compuestos permiten comparaciones cuantitativas entre regiones y facilitan la priorización de recursos para mitigación de riesgo.

Cabe destacar también el análisis hecho con series temporales de gas radón \cite{tareen2019descriptive} que más allá de solo buscar patrones en magnitudes, epicentros, fechas y profundidades, busca identificar patrones en la concentración de gas radón en el subsuelo previos a la ocurrencia de sismos y plantea el que estos puedan actuar como posibles precursores sísmicos.

Los artículos revisados abarcan distintas áreas geográficas del planeta, como la costa occidental de México \cite{barrientos2007analisis,sawires2023probabilistic,zuniga2022first}, el Cuerno de África (comprendido por varios países, entre ellos Etiopía, Sudán y Uganda) \cite{abebe2023earthquakes}, Suiza en contexto de sismicidad inducida \cite{mignan2021best}, Irán con análisis multi-regional \cite{yaghmaeisakbegh2022regional}, Taiwán \cite{phung2020ground}, Japón y otras regiones de Asia \cite{velascoherrera2022long}, el Arco del Himalaya occidental \cite{singh2021ground}, Pakistán \cite{tareen2019descriptive}, Italia con validación retrospectiva de modelos \cite{convertito2020combining} y regiones de Norteamérica, Sudamérica y China \cite{velascoherrera2022long}.

También podemos encontrar trabajos con un enfoque conceptual y metodológico que revisan teorías de predicción sísmica y su evolución a lo largo del tiempo \cite{galbanrodriguez2021theoretical}. Particularmente relevante es la revisión de \citeasnoun{coles2021extreme}, que actualiza las recomendaciones metodológicas sobre teoría de valores extremos veinte años después del trabajo seminal de \citeasnoun{coles2001introduction}, incorporando avances computacionales y estadísticos recientes e integrando aplicaciones a cambio climático, desastres naturales y eventos sísmicos.

En el contexto mexicano específico, varios estudios recientes han aplicado metodologías de valores extremos y análisis de brechas sísmicas a diferentes regiones del país. \citeasnoun{ramirezgaytan2021earthquake} se enfocan en la brecha sísmica de Michoacán utilizando más de un siglo de datos del SSN, mientras que \citeasnoun{zuniga2022first} proponen una regionalización sismotectónica completa del país que caracteriza específicamente las zonas de Oaxaca, Guerrero, Michoacán y Chiapas mediante parámetros de recurrencia y estimaciones de peligrosidad. \citeasnoun{singh2020deadly}, con autores pertenecientes al SSN-UNAM, proporcionan validación retrospectiva de modelos probabilísticos mediante el análisis del sismo de Puebla 2017, enfatizando la importancia de incorporar memoria temporal en modelos sísmicos mexicanos. Estos trabajos demuestran la madurez creciente de la aplicación de teoría de valores extremos al contexto sísmico mexicano y proporcionan parámetros regionales específicos que fundamentan estimaciones de peligrosidad actualizadas.

\section{Análisis del estado del arte}

\noindent
La revisión del estado del arte muestra que la predicción y evaluación del peligro sísmico se ha abordado desde múltiples perspectivas: modelos probabilistas clásicos, distribuciones estadísticas avanzadas de valores extremos (Gumbel, Weibull, GEV), enfoques de inteligencia artificial y aprendizaje profundo, así como indicadores geofísicos como el gas radón. Los trabajos revisados muestran una tendencia hacia la integración de métodos estadísticos rigurosos con técnicas modernas de machine learning, lo que permite mejorar la precisión de las estimaciones y adaptarlas a contextos regionales específicos. Un hallazgo relevante es la consolidación de la teoría de valores extremos \cite{coles2001introduction,coles2021extreme} como marco teórico robusto para el análisis de eventos sísmicos raros de gran magnitud, particularmente mediante el método de máximos anuales que ha demostrado ser más confiable que enfoques alternativos para tamaños de muestra típicos en sismología \cite{bommier2023peak}. Este panorama refleja un campo en constante evolución, donde la combinación de enfoques tradicionales y emergentes constituye la base para avanzar hacia predicciones más confiables y útiles para la mitigación del riesgo sísmico.

Desde una perspectiva metodológica, se identifica un consenso creciente sobre las mejores prácticas para el análisis probabilístico de peligrosidad sísmica: (1) empleo de magnitudes máximas anuales como variable de análisis para conjuntos de datos con menos de 150 años de registros \cite{bommier2023peak}, (2) selección de distribución óptima por región mediante criterios BIC o AIC validados con pruebas de bondad de ajuste múltiples \cite{yaghmaeisakbegh2022regional}, (3) estimación de parámetros mediante máxima verosimilitud \cite{mignan2021best}, (4) cuantificación de incertidumbre mediante bootstrap paramétrico con 10,000 iteraciones \cite{papalexiou2020random}, (5) cálculo de niveles de retorno para períodos estándar (10, 20, 50, 100 años) con intervalos de confianza al 95\%, (6) incorporación de análisis temporal mediante índices de proximidad y coeficientes de variación de recurrencia \cite{sanchezsilva2020real,ramirezgaytan2021earthquake}, y (7) validación retrospectiva con eventos recientes \cite{singh2020deadly}. La adopción sistemática de estas prácticas en el contexto mexicano, particularmente para las regiones de mayor actividad sísmica en la costa del Pacífico, representa una oportunidad para mejorar significativamente la robustez y confiabilidad de las estimaciones de peligrosidad a nivel nacional.