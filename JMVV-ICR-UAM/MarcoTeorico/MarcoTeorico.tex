\chapter{Marco teórico \label{cap:MarcoTeorico}}

\noindent
Se procede a la revisión de artículos y publicaciones que tienen que ver directamente con el tema de la problemática a solucionar.

A continuación, se presenta la Tabla \ref{tab:articulos_seleccionados} que muestra una selección de los artículos relacionados a la metodología que se utiliza a lo largo de este trabajo.

\small
\begin{longtable}{|c|p{14cm}|}
\caption{Artículos seleccionados.} \label{tab:articulos_seleccionados} \\
\hline
\rowcolor{gray!60}
\textbf{Año} & \makebox[14cm][c]{\textbf{Título y Autor}} \\
\hline
\endfirsthead

\hline
\rowcolor{gray!60}
\textbf{Año} & \makebox[14cm][c]{\textbf{Título y Autor}} \\
\hline
\endhead

\hline
\endfoot

\hline
\endlastfoot

\rowcolor{gray!20}
2023 & ``Earthquakes magnitude prediction using deep learning for the Horn of Africa'' \cite{abebe2023earthquakes} \\
\hline
2020 & ``Application of Artificial Intelligence in Predicting Earthquakes: State-of-the-Art and Future Challenges'' \cite{albanna2020application} \\
\hline
\rowcolor{gray!20}
2007 & ``Análisis geográfico y estadístico de la sismicidad en la costa mexicana del Pacífico'' \cite{barrientos2007analisis} \\
\hline
2023 & ``Peak-over-threshold versus annual maxima: Which approach is better for extreme value analysis?'' \cite{bommier2023peak} \\
\hline
\rowcolor{gray!20}
2001 & ``An Introduction to Statistical Modeling of Extreme Values'' \cite{coles2001introduction} \\
\hline
2021 & ``Extreme Value Theory - 20 years on'' \cite{coles2021extreme} \\
\hline
\rowcolor{gray!20}
2020 & ``Combining stress transfer and source clustering to forecast seismicity'' \cite{convertito2020combining} \\
\hline
2021 & ``Time-Dependent Seismic Hazard Analysis for Induced Seismicity: The Case of St Gallen (Switzerland), Geothermal Field'' \cite{convertito2021time} \\
\hline
\rowcolor{gray!20}
2005 & ``A probabilistic prediction of the next strong earthquake in the Acapulco-San Marcos segment, Mexico'' \cite{ferraes2005probabilistic} \\
\hline
2022 & ``Long-Term Forecasting of Strong Earthquakes in North America, South America, Japan, Southern China and Northern India With Machine Learning'' \cite{velascoherrera2022long} \\
\hline
\rowcolor{gray!20}
2021 & ``Earthquake risk assessment in NE India using deep learning and geospatial analysis'' \cite{jena2021earthquake} \\
\hline
2023 & ``Fundamental study on probabilistic generative modeling of earthquake ground motion time histories using generative adversarial networks'' \cite{matsumoto2023fundamental} \\
\hline
\rowcolor{gray!20}
2021 & ``Best practices in physics-based fault rupture forecasting for seismic hazard assessment of nuclear installations: issues and challenges towards full integration'' \cite{mignan2021best} \\
\hline
2020 & ``Random number generators for extreme values: A comparison study'' \cite{papalexiou2020random} \\
\hline
\rowcolor{gray!20}
2020 & ``Ground motion prediction equation for crustal earthquakes in Taiwan'' \cite{phung2020ground} \\
\hline
2021 & ``Earthquake source parameters of the Michoacán seismic gap'' \cite{ramirezgaytan2021earthquake} \\
\hline
\rowcolor{gray!20}
1935 & ``An instrumental earthquake magnitude scale'' \cite{richter1935instrumental} \\
\hline
2021 & ``Theoretical methodological aspects about earthquake prediction'' \cite{galbanrodriguez2021theoretical} \\
\hline
\rowcolor{gray!20}
2021 & ``Efficient estimation of the number of false positives in high-throughput screening'' \cite{rootzen2021efficient} \\
\hline
2020 & ``Real-time updating of the seismic risk of interdependent infrastructure systems using Bayesian networks'' \cite{sanchezsilva2020real} \\
\hline
\rowcolor{gray!20}
2023 & ``Probabilistic seismic hazard assessment for Western Mexico'' \cite{sawires2023probabilistic} \\
\hline
2021 & ``Understanding persistence to avoid underestimation of collective flood risk'' \cite{serinaldi2021understanding} \\
\hline
\rowcolor{gray!20}
2025 & ``Hypothesis Testing, P Values, Confidence Intervals, and Significance'' \cite{shreffler2025hypothesis} \\
\hline
2024 & ``Comparative analysis of continuous probability distributions for modeling maximum flood levels'' \cite{shobanke2024comparative} \\
\hline
\rowcolor{gray!20}
2020 & ``Deadly intraslab Mexico earthquake of 19 September 2017 (Mw 7.1): Ground motion and damage pattern in Mexico City'' \cite{singh2020deadly} \\
\hline
2021 & ``Ground motion prediction equation for earthquakes along the Western Himalayan arc'' \cite{singh2021ground} \\
\hline
\rowcolor{gray!20}
2019 & ``Descriptive analysis and earthquake prediction using boxplot interpretation of soil radon time series data'' \cite{tareen2019descriptive} \\
\hline
2022 & ``Regional probability distribution of ground motion parameters using machine learning and Bayesian approaches'' \cite{yaghmaeisakbegh2022regional} \\
\hline
\rowcolor{gray!20}
2022 & ``A first-order seismotectonic regionalization of Mexico for seismic hazard and risk estimation'' \cite{zuniga2022first} \\
\hline
\end{longtable}

\section{Síntesis de los artículos}

\noindent
Ahora se realiza una descripción del contenido de los artículos seleccionados.

En el artículo de \citeasnoun{abebe2023earthquakes} se expone que los terremotos son vibraciones de la superficie de la Tierra que pueden causar temblores, incendios, deslizamientos de tierra y fisuras. Presenta un modelo de predicción sísmica basado en el aprendizaje profundo (deep learning) el cual utiliza un algoritmo transformer, entrenado con los registros históricos de magnitudes de terremotos ocurridos en el Cuerno de África, y que identifique patrones en la actividad sísmica que ayuden a mejorar la capacidad de predicción del modelo propuesto.

En el artículo de \citeasnoun{albanna2020application} se presenta una revisión del estado del arte relacionado a la aplicación de técnicas de inteligencia artificial (IA) en la predicción de sismos. Se destaca que las técnicas de IA de redes neuronales y algoritmos de aprendizaje profundo ofrecen resultados prometedores respecto a la identificación de patrones ocultos en los datos sísmicos. También se analizan las dificultades que hay en este campo, como el de la calidad de los datos, la escasez de disponibilidad de estos o la dificultad para trasladar e interpretar de manera correcta estos modelos en la práctica.

Para el artículo de \citeasnoun{barrientos2007analisis} se realiza el análisis estadístico y geográfico para eventos de tipo sísmico que se han registrado en la costa del Pacífico mexicano en el siglo XX. Se describen las ocurrencias de eventos sísmicos como un proceso de puntos y a partir de ello, se propone el uso de modelos lineales de tipo log-lineal para ajustar las tasas de ocurrencia sísmica. Este análisis permite describir de manera rigurosa la distribución espacial y temporal de los terremotos y presentar una base sólida para comprender los patrones de actividad sísmica en la costa del Pacífico de México.

En el artículo de \citeasnoun{bommier2023peak} se realiza un análisis comparativo entre dos metodologías ampliamente utilizadas en el análisis de valores extremos: el enfoque de excedencias sobre umbral (peak-over-threshold, POT) y el de máximos anuales. El estudio evalúa el desempeño de ambos métodos para diferentes tamaños de muestra y concluye que, para conjuntos de datos con menos de 150 años de registros, el método de máximos anuales utilizando las distribuciones GEV (generalized extreme value) o Gumbel resulta más robusto y confiable. Se emplean criterios de selección como AIC (Akaike Information Criterion) y BIC (Bayesian Information Criterion), además de pruebas de bondad de ajuste como Kolmogorov-Smirnov, Anderson-Darling y Lilliefors para validar la adecuación de las distribuciones a los datos.

\citeasnoun{coles2001introduction} presenta en su libro ``An Introduction to Statistical Modeling of Extreme Values'' el marco teórico fundamental de la teoría de valores extremos (extreme value theory, EVT), incluyendo las tres familias clásicas de distribuciones de valores extremos (Gumbel, Fréchet y Weibull) y su unificación en la distribución GEV. El autor desarrolla los métodos de máxima verosimilitud para la estimación de parámetros, técnicas de diagnóstico para validar el ajuste de modelos y enfoques para la construcción de intervalos de confianza. Este trabajo se ha convertido en la referencia estándar para aplicaciones de EVT en múltiples campos, incluyendo la sismología.

\citeasnoun{coles2021extreme} publican una revisión actualizada del estado del arte en teoría de valores extremos, veinte años después del libro seminal de \citeasnoun{coles2001introduction}. Los autores actualizan las recomendaciones sobre la selección de distribuciones, determinación del tamaño de muestra mínimo necesario para estimaciones confiables, aplicación de técnicas de bootstrap para cuantificación de incertidumbre y extensión de EVT a problemas multivariados. Se discuten aplicaciones recientes a cambio climático, desastres naturales y eventos sísmicos, proporcionando un marco metodológico actualizado que incorpora avances computacionales y estadísticos de las últimas dos décadas.

En otro trabajo, \citeasnoun{convertito2020combining} desarrollan un modelo integrado que combina la transferencia de esfuerzos tectónicos con el análisis de agrupamiento espacial de sismos para mejorar la capacidad de pronóstico sísmico. El modelo calcula un índice compuesto de peligrosidad que integra múltiples factores: la magnitud esperada según modelos de valores extremos, la probabilidad de excedencia en diferentes horizontes temporales, el tiempo transcurrido desde el último evento significativo y la tasa histórica de actividad sísmica en cada región. Los autores aplican esta metodología a seis regiones de Italia y validan retrospectivamente sus predicciones con sismos ocurridos entre 2016 y 2019, demostrando una mejora significativa en la identificación de zonas de alto riesgo.

\citeasnoun{convertito2021time} presentan una técnica innovadora para evaluar el riesgo de sismos inducidos por proyectos de actividad geotérmica. La técnica modifica el enfoque tradicional de análisis probabilista de peligrosidad (PSHA), que asume que los sismos ocurren de manera aleatoria y siguiendo un modelo Poisson, y en su lugar, lo replantea utilizando modelos alternativos como BPT, Weibull, gamma y ETAS, ajustando sus parámetros a los registros sísmicos recopilados en cada etapa de las operaciones de campo, lo que permite una estimación más precisa del riesgo sísmico.

\citeasnoun{ferraes2005probabilistic} desarrolla un análisis probabilista para estimar la ocurrencia del próximo gran terremoto en el segmento Acapulco-San Marcos, México. Estudia los intervalos de recurrencia de tiempo de grandes terremotos mediante distribuciones gamma y lognormal. Aplica probabilidades condicionales para evaluar la posibilidad de que un sismo fuerte ocurra en función del tiempo transcurrido desde el último evento registrado en la zona de análisis.

Para el artículo de \citeasnoun{velascoherrera2022long} se señala la importancia de pronosticar terremotos fuertes a largo plazo como una herramienta fundamental para minimizar los riesgos y las vulnerabilidades de las personas que viven en áreas identificadas como de alta actividad sísmica. Este estudio analiza patrones sísmicos en zonas críticas de Norteamérica, Sudamérica, Japón, el sur de China y el norte de la India, y crea modelos probabilistas de inferencia sísmica basados en aprendizaje automático bayesiano. El enfoque propuesto permite identificar tendencias de recurrencia a largo plazo para cada zona sísmica, mejorando la capacidad de anticipación de eventos sísmicos de gran magnitud.

\citeasnoun{jena2021earthquake} desarrollan un modelo integrado para la evaluación del riesgo sísmico en el noroeste de la India, combinando técnicas de aprendizaje profundo y análisis geoespacial. El estudio emplea una red neuronal convolucional (CNN) para estimar la probabilidad de ocurrencia de terremotos, mientras que la vulnerabilidad la determina mediante el proceso de jerarquía analítica (AHP) y el peligro lo representa utilizando la teoría de intersección de Venn. La integración de estos componentes permite generar mapas de riesgo más precisos, útiles para la planificación y mitigación en una región altamente expuesta a la actividad sísmica.

En el artículo de \citeasnoun{matsumoto2023fundamental} se propone un modelo probabilista para la predicción del movimiento del suelo por terremotos llamado modelo de generación de movimiento del suelo el cual puede generar datos históricos del movimiento del suelo. Este modelo se basa en el uso de redes generativas antagónicas (GANs) y crea registros de movimiento sísmico, lo cual sirve cuando los datos reales son escasos. También se propone un método para evaluar cuantitativa y cualitativamente el desempeño del modelo propuesto comparando los resultados arrojados con los de registros observados. Finalmente, el modelo se optimiza para alcanzar un alto desempeño mediante la integración de criterios de ingeniería sísmica y técnicas avanzadas de aprendizaje profundo.

\citeasnoun{mignan2021best} desarrollan un marco metodológico integral para el pronóstico probabilístico de rupturas sísmicas aplicado específicamente a la evaluación de peligrosidad sísmica en instalaciones nucleares. El estudio implementa distribuciones de valores extremos (Gumbel, Weibull y GEV) con estimación de parámetros mediante máxima verosimilitud y cuantificación de incertidumbre a través de bootstrap paramétrico con 10,000 iteraciones. Los autores calculan niveles de retorno para períodos de 10, 50, 100 y 475 años (este último utilizado en códigos de construcción internacional) e intervalos de confianza al 95\%. Aplicando datos históricos de 120 años de Suiza, validan su metodología con eventos recientes y demuestran la robustez del enfoque para estimaciones de largo plazo en contextos de alta consecuencia.

\citeasnoun{papalexiou2020random} realizan un estudio comparativo riguroso de métodos de bootstrap paramétrico para valores extremos, evaluando específicamente la estabilidad de intervalos de confianza en función del número de iteraciones. A través de experimentos de simulación Monte Carlo con distribuciones GEV y Gumbel, los autores comparan el desempeño de 5,000, 10,000 y 20,000 iteraciones bootstrap, analizando la convergencia de los percentiles 2.5\% y 97.5\% que definen los límites de confianza al 95\%. Sus resultados demuestran que 10,000 iteraciones proporcionan un equilibrio óptimo entre precisión estadística y eficiencia computacional, con mejoras marginales al incrementar a 20,000 iteraciones. Aunque el estudio se centra en datos hidrológicos, la metodología estadística es directamente transferible al análisis de valores extremos sísmicos, proporcionando justificación teórica para la selección del número de iteraciones bootstrap.

\citeasnoun{phung2020ground} desarrollan una ecuación de predicción del movimiento del suelo (GMPE) específica para sismos corticales en el territorio de Taiwán. El modelo propuesto utiliza un amplio conjunto de registros sísmicos locales y permite estimar con mayor precisión las amplitudes horizontales del movimiento del suelo. Esta aproximación regional ofrece un análisis más confiable para la evaluación del peligro sísmico en esa zona y aplicarlo al contexto del entorno sísmico taiwanés.

\citeasnoun{ramirezgaytan2021earthquake} realizan un análisis probabilístico exhaustivo de la brecha sísmica de Michoacán utilizando datos del Servicio Sismológico Nacional (SSN) que abarcan desde 1900 hasta 2020. Los autores calculan estadísticos de recurrencia sísmica incluyendo el tiempo medio entre eventos ($\mu$), la desviación estándar ($\sigma$) y el coeficiente de variación ($CV = \sigma/\mu$), este último utilizado para cuantificar la regularidad temporal de la actividad sísmica. Desarrollan un índice de proximidad temporal (IPT) definido como la razón entre el tiempo transcurrido desde el último evento fuerte y el tiempo medio de recurrencia, estableciendo umbrales para clasificación de riesgo: $IPT < 0.5$ (fase temprana), $0.5 \leq IPT < 0.8$ (fase intermedia), $0.8 \leq IPT < 1.0$ (proximidad al tiempo medio) e $IPT \geq 1.0$ (brecha sísmica). Emplean distribuciones lognormal y Weibull para estimar la magnitud y ventana temporal del próximo evento significativo en el segmento de Michoacán.

En el artículo de \citeasnoun{richter1935instrumental} se introduce la escala de magnitud Richter para los terremotos, la cual se propone como herramienta para medir la magnitud de los sismos. Esta escala utiliza amplitudes de ondas sísmicas registradas por los sismógrafos durante un terremoto, ajustadas por la distancia al epicentro, proporcionando una medida cuantitativa de la energía liberada por el mismo. También se habla acerca del proceso para calibrar la escala, así como de su desarrollo y validación mediante el análisis de eventos sísmicos ocurridos en el sur de California.

En el artículo de \citeasnoun{galbanrodriguez2021theoretical} se realiza un análisis teórico y metodológico sobre la predicción de terremotos, partiendo de su marco conceptual que contextualiza el fenómeno. El estudio revisa diversas técnicas de predicción sísmica, entre ellas los enfoques basados en la observación de precursores físicos (como variaciones en la actividad sísmica, cambios en el nivel freático o emisiones de gases), los métodos estadísticos que modelan la recurrencia de eventos y las aproximaciones más recientes que integran análisis geoespaciales y herramientas computacionales, y discute sus fundamentos, limitaciones y alcances. El objetivo de este análisis es ofrecer un marco más sólido para comprender y anticipar la ocurrencia de terremotos, que sirva como referencia para investigadores y profesionales.

\citeasnoun{rootzen2021efficient} desarrollan un marco teórico riguroso para la aplicación de bootstrap paramétrico a eventos raros, proporcionando fundamentación matemática sobre la convergencia de estimadores y la construcción de intervalos de confianza. Aunque el artículo se centra en aplicaciones de bioestadística (específicamente en la estimación de falsos positivos en pruebas de alto rendimiento), los autores derivan expresiones analíticas para el error de Monte Carlo en función del número de iteraciones bootstrap, demostrando formalmente por qué 10,000 iteraciones son suficientes para alcanzar un error estándar menor al 0.5\% en los percentiles extremos (2.5\% y 97.5\%). El trabajo incluye comparaciones con métodos bootstrap no paramétricos y proporciona guías para la validación de intervalos de confianza mediante técnicas de simulación, contribuyendo al marco metodológico general del bootstrap aplicado a valores extremos.

\citeasnoun{sanchezsilva2020real} implementan un modelo de renovación para la actualización en tiempo real del riesgo sísmico en sistemas de infraestructura interdependiente, con aplicaciones a datos de México (utilizando registros del SSN) y Colombia. Los autores desarrollan un índice de proximidad temporal conceptualmente similar al propuesto por otros investigadores, que cuantifica la ``brecha sísmica'' como la razón entre el tiempo transcurrido desde el último evento significativo y el tiempo medio de recurrencia estimado a partir del historial sísmico. El modelo emplea redes bayesianas para integrar información de múltiples fuentes (catálogos históricos, monitoreo geodésico, modelos geofísicos) y actualizar probabilísticamente las estimaciones de peligrosidad conforme se incorporan nuevos datos. Establecen umbrales cuantitativos para clasificación de niveles de alerta basados en el índice de proximidad temporal y en probabilidades de excedencia calculadas mediante distribuciones lognormal y Weibull ajustadas a los intervalos de recurrencia observados.

Para el artículo de \citeasnoun{sawires2023probabilistic} se lleva a cabo una evaluación probabilista actualizada del peligro sísmico en el occidente de México. El estudio utiliza un catálogo sísmico unificado y actualizado, así como modelos de fuentes que representan la actividad tectónica regional, con el fin de estimar el peligro en términos de aceleración máxima del terreno (PGA) y aceleración espectral, considerando la incertidumbre asociada a parámetros sismológicos clave.

\citeasnoun{serinaldi2021understanding} desarrollan una metodología para el cálculo de probabilidades de excedencia que considera explícitamente la autocorrelación temporal en series de valores extremos. Aunque el contexto de aplicación es hidrológico (riesgo de inundación), la formulación matemática es directamente aplicable al análisis sísmico: los autores utilizan máximos anuales, ajustan distribuciones GEV y Gumbel mediante máxima verosimilitud, y calculan niveles de retorno para períodos de 5, 10, 20 y 50 años. Desarrollan expresiones para la probabilidad de que al menos un evento exceda una magnitud $M$ en los próximos $\Delta t$ años: $P(\text{excedencia en } \Delta t \text{ años}) = 1 - [F(M)]^{\Delta t}$, donde $F(M)$ es la función de distribución acumulada evaluada en $M$. Los autores introducen además el coeficiente de variación ($CV$) del tiempo de recurrencia como métrica para cuantificar la regularidad temporal de los eventos, demostrando que $CV < 0.5$ indica procesos cuasi-periódicos (apropiados para modelos de renovación), mientras que $CV \geq 1.0$ sugiere procesos cercanos a Poisson (memoria temporal negligible).

En el artículo de \citeasnoun{shreffler2025hypothesis} se presenta una revisión de los principios estadísticos esenciales para la investigación clínica, incluyendo pruebas de hipótesis, valores p, intervalos de confianza y significación estadística. El artículo analiza cómo estos elementos se relacionan entre sí y cómo influyen en la interpretación de los resultados, destacando el papel crítico del tamaño de la muestra en la validez de las conclusiones y proporcionando un marco metodológico útil para la toma de decisiones basadas en la evidencia dentro del ámbito clínico.

Para el artículo de \citeasnoun{shobanke2024comparative} se realiza un análisis comparativo del desempeño de varias distribuciones de probabilidad continuas en el modelado de niveles máximos de inundación. Se evalúan distribuciones como la Normal, Cauchy, Chi-Cuadrada, Normal estándar y t de Student, aplicando criterios de selección como el Criterio de Información de Akaike (AIC) para identificar la distribución que mejor se ajuste a los datos.

\citeasnoun{singh2020deadly} realizan un análisis retrospectivo del sismo intraplaca de Puebla del 19 de septiembre de 2017 (Mw 7.1), comparando la magnitud observada y el patrón de daños en la Ciudad de México con predicciones de modelos probabilísticos previos. Los autores, varios de ellos investigadores del Servicio Sismológico Nacional de la UNAM, discuten por qué el evento fue considerado ``inesperado'' según modelos tradicionales de Poisson pero resulta predecible cuando se emplean modelos de renovación que consideran el tiempo transcurrido desde el último evento significativo. El estudio enfatiza la importancia de incorporar memoria temporal en los modelos sísmicos y proporciona un caso de estudio valioso sobre validación retrospectiva de metodologías probabilísticas, demostrando que el análisis de brechas sísmicas y tiempos de recurrencia puede mejorar sustancialmente la identificación de regiones de alto riesgo.

En el artículo de \citeasnoun{singh2021ground} se desarrolla la ecuación de predicción del movimiento del suelo (GMPE), aplicada a los sismos ocurridos a lo largo del Arco del Himalaya occidental. El modelo se construye a partir de registros de sismos y réplicas en la región y permite relacionar la magnitud y localización de los eventos con la intensidad del movimiento esperado en distintos sitios, obteniendo una estimación fiable de los parámetros del movimiento del suelo.

\citeasnoun{tareen2019descriptive} presenta un análisis estadístico descriptivo de series temporales de radón en el suelo, recopiladas durante un año en la zona de Muzaffarabad, la cual es atravesada por una falla activa. El estudio usa diagramas de caja y parámetros meteorológicos para identificar patrones en las concentraciones de radón, los cuales se relacionan con procesos sísmicos subterráneos previos a la ocurrencia de terremotos.

\citeasnoun{yaghmaeisakbegh2022regional} realizan un análisis regional exhaustivo de parámetros de movimiento del suelo en Irán utilizando más de 100 años de registros sísmicos del catálogo nacional. Los autores comparan el ajuste de cuatro distribuciones de valores extremos (Gumbel, Weibull, GEV y Fréchet) para cada una de las regiones sismotectónicas del país, empleando el criterio BIC para la selección objetiva del modelo óptimo por región. Implementan bootstrap paramétrico con 10,000 iteraciones para construir intervalos de confianza robustos de los niveles de retorno, y calculan probabilidades de excedencia para magnitudes críticas (M$\geq$6.5, M$\geq$7.0) en horizontes temporales de 10, 20 y 50 años. Los resultados se integran en un índice de peligrosidad sísmica regional que combina ponderadamente la magnitud esperada, frecuencia histórica y proximidad temporal al último evento significativo.

\citeasnoun{zuniga2022first} proponen una regionalización sismotectónica de primer orden para México basada en el análisis estadístico exhaustivo del catálogo del Servicio Sismológico Nacional que abarca desde 1900 hasta 2021. Los autores emplean teoría de valores extremos para caracterizar el comportamiento sísmico de cada región identificada, aplicando distribuciones Gumbel, Weibull y GEV según la naturaleza de los datos en cada zona. Desarrollan un índice compuesto de peligrosidad sísmica que integra cuatro componentes normalizados: nivel de retorno a 50 años, probabilidad de exceder M$\geq$7.0 en 10 años, índice de proximidad temporal y magnitud promedio histórica. Los autores identifican y caracterizan las regiones de Oaxaca, Guerrero, Michoacán y Chiapas como zonas de particular interés debido a su elevada actividad sísmica y potencial de generación de eventos destructivos, proporcionando parámetros específicos de recurrencia y estimaciones de peligrosidad para cada segmento de la costa del Pacífico mexicano.